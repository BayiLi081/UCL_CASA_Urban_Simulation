{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENVGSC5 - UCL CASA: Urban Simulation\n",
    "\n",
    "# Constrained Spatial Interaction Models\n",
    "\n",
    "This notebook largely reproduces Adam Dennett's Rpubs guide to constrained spatial interaction models in Python. See his original R version [here](https://rpubs.com/adam_dennett/259068) and the equivalent Python code [here](https://github.com/danlewis85/UCL_CASA_Urban_Simulation/blob/master/Unconstrained%20Spatial%20Interaction%20Models.ipynb)\n",
    "\n",
    "NB Although the content is very similar, there are a couple of changes made for convenience - such as removing the intercept from the Poisson GLMs. As with the previous Python notebook, slight differences in the distance measurements between Python and R mean that results are almost, but not exactly the same as in Dr. Dennett's R code.\n",
    "\n",
    "## Recap\n",
    "\n",
    "In the previous practical we learned all about the unconstrained spatial interaction model; how we can use it to estimate flows in a system using values for origin emissiveness or destination attractiveness; how we can tweak the estimates the model produces through adjusting either the parameters associated with the predictor variables, or though using different predictor variables or updating their values; and how we can improve the fits of the model further by calibrating the parameters through using a Poisson regression model.\n",
    "\n",
    "We saw that even after calibration, our model still only explained around 60% of the variation in the flows that we observed in our system, so can we do any better? Well yes, yes we can!\n",
    "\n",
    "## Constrained Models\n",
    "\n",
    "If we return to [Alan Wilson’s 1971 paper](http://journals.sagepub.com/doi/abs/10.1068/a030001), he introduces a full family of spatial interaction models of which the unconstrained model is just the start. And indeed since then, there have been all number of incremental advances and alternatives (such as [Stewart Fotheringham’s Competing Destinations models](https://asu.pure.elsevier.com/en/publications/a-new-set-of-spatial-interaction-models-the-theory-of-competing-d), [Pooler’s production/attraction/cost relaxed models](http://journals.sagepub.com/doi/abs/10.1177/030913259401800102), [Stillwell’s origin/destination parameter specific models](http://journals.sagepub.com/doi/pdf/10.1068/a101187) and [Dennett and Wilson’s own multi-level model](http://journals.sagepub.com/doi/pdf/10.1068/a45398) (to name just a few).\n",
    "\n",
    "In this session we will explore the rest of Wilson’s family - the Production (origin) Constrained Model; the Attraction (destination) constrained model; and the Doubly Constrained Model.\n",
    "\n",
    "We will see how we can, again, use a Poisson regression model in R to calibrate these models and how, once calibrated, we can use the models in different contexts, such as Land Use Transportation Interaction (LUTI) modelling, retail modelling and migration modelling.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "We need fewer Python libraries than the previous practical as we are using a copy of the dataset that we saved in the last practical and hence have completed all the heavy lifting! Pandas is what we use to store our dataset, matplotlib is for simple plots, numpy is used for some numerical operations, and statsmodels gives us our Poisson GLMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cdata dataset that we saved in practical 1\n",
    "cdata = pd.read_csv('cdata.csv',index_col = 0)\n",
    "\n",
    "# Now create a subset of flows\n",
    "flows = [\"00AA\", \"00AB\", \"00AC\", \"00AD\", \"00AE\", \"00AF\", \"00AG\"]\n",
    "\n",
    "# from cdata, we want the 42 flows that start and end as one of these 7 flows, but not the 7 self flows\n",
    "# The subset selection has 3 parts: 1) OrigCode in flows; 2) DestCode in flows; 3) Origcode not equal to DestCode.\n",
    "cdatasub = cdata[cdata['OrigCode'].isin(flows) & cdata['DestCode'].isin(flows) & (cdata['OrigCode'] != cdata['DestCode'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5467.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12080.0</td>\n",
       "      <td>7709.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>362.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>40.0</td>\n",
       "      <td>6124.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8105.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>134.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3199.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>9855.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   194.0    96.0   178.0     66.0   \n",
       "Barnet                                96.0     0.0    34.0  5467.0     76.0   \n",
       "Bexley                               362.0   132.0     0.0   144.0   4998.0   \n",
       "Brent                                 40.0  6124.0    28.0     0.0     66.0   \n",
       "Bromley                              134.0   162.0  3199.0   201.0      0.0   \n",
       "Camden                                36.0  1496.0    32.0  1350.0     60.0   \n",
       "City of London                         6.0    14.0     0.0    16.0      0.0   \n",
       "All                                  674.0  8122.0  3389.0  7356.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1500.0          3641.0   5675.0  \n",
       "Barnet                12080.0          7709.0  25462.0  \n",
       "Bexley                 2470.0          6580.0  14686.0  \n",
       "Brent                  8105.0          4145.0  18508.0  \n",
       "Bromley                3780.0          9855.0  17331.0  \n",
       "Camden                    0.0          8795.0  11769.0  \n",
       "City of London          335.0             0.0    371.0  \n",
       "All                   28270.0         40725.0  93802.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a pivot table to look at the flow matrix\n",
    "cdatasubmat = pd.pivot_table(cdatasub,values='Total',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)\n",
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Production and Attraction Constrained Models\n",
    "\n",
    "Wilson’s real contribution to the field was in noticing that the unconstrained gravity model was sub-optimal as it did not make use of all of the available data in the system we are studying.\n",
    "\n",
    "If we recall, the estimates from our unconstrained model, none of the estimates summed to the observed in and out-flow totals. Our estiamtes only summed to the grand total of flows, but this is because we were really fitting a ‘total constrained’ model which used $k$ - the constant of proportionality - to ensure everything more or less added up (subject to rounding errors).\n",
    "\n",
    "Where we have a full flow matrix to calibrate parameters, we can incorporate the row (origin) totals, column (destination) totals or both origin and destination totals to _constrain_ our flow estimates to these known values.\n",
    "\n",
    "There are various reasons for wanting to do this, for example:\n",
    "\n",
    "1. If we are interested in flows of money into businesses or customers into shops, we might have information on the amount of disposable income and shopping habits of the people living in different areas from loyalty card data. This is known information about our origins and so we could constrain our spatial interaction model to this known information - we can make the assumption that this level of disposable income remains the same. We can then use other information about the attractiveness of places these people might like to shop in (store size, variety / specialism of goods etc.), to estimate how much money a new store opening in the area might make, or if a new out-of-town shopping centre opens, how much it might affect the business of shops in the town centre. This is what is known in the literature as the ‘retail model’ and is perhaps the most common example of a __Production (origin) Constrained Spatial Interaction Model.__\n",
    "\n",
    "2. We might be interested in understanding the impact of a large new employer in an area on the local flows of traffic or on the demand for new worker accommodation nearby. A good example of where this might be the case is with large new infrastructure developments like new airports. For example, before the go-ahead for the new third runway at Heathrow was given, one option being considered was a new runway in the Thames Estuary. If a new airport was built here, what would be the potential impact on transport flows in the area and where might workers commute from? This sort of scenario could be tested with an __Attraction (destination) Constrained Spatial Interaction Model__ where the number of new jobs in a destination is known (as well as jobs in the surrounding area) and the model could be used to estimate where the workers will be drawn from (and their likely travel-to-work patterns). This model is exactly the sort of model Land Use Transport Interaction (LUTI) model that was constructed by the Mechanicity Team in CASA - details [here](http://www.mechanicity.info/research/land-use-transport-interaction-modelling/) if you are interested…\n",
    "\n",
    "3. We might be interested in understanding the changing patterns of commuting or migration over time. Data from the Census allows us to know an accurate snap-shot of migrating and commuting patterns every 10 years. In these full data matrices, we know both the numbers of commuters/migrants leaving origins and arriving at destinations as well as the interactions between them. If we constrain our model estimates to this known information at origin and destination, we can examine various things, including:\n",
    " 1. the ways that the patterns of commuting/migration differ from the model predictions - where we might get more migrant/commuter flows than we would expect\n",
    " 2. how the model parameters vary over time - for example how does distance / cost of travel affect flows over time? Are people prepared to travel further or less far than before?\n",
    " \n",
    "# 2. Production Constrained Model\n",
    "\n",
    "1 $$T_{ij} = A_{i}O_{i}W_{j}^{\\alpha}d_{ij}^{-\\beta}$$\n",
    "where\n",
    "\n",
    "2 $$O_{i} = \\sum_{j}T_{ij}$$\n",
    "and\n",
    "\n",
    "3 $$A_{i} = \\frac{1}{\\sum_{j}W_{j}^{\\alpha}d_{ij}^{-\\beta}}$$\n",
    "\n",
    "In the production-constrained model, $O_{i}$ does not have a parameter as it is a known constraint, although it could be dissaggregated and receive a superscript index. $A_{i}$ is known as a _balancing factor_ and is a vector of values which relate to each origin, $i$, which do a similar job to $k$ in the unconstrained/total constrained model. Specifically, $A_{i}$ ensures that flow estimates from each origin sum to the known totals, $O_{i}$ rather than just the overall total. This constraint is given by equation 2 above.\n",
    "\n",
    "Now at this point, we could calculate all of the $O_{i}$s and $A_{i}$s by hand for our sample system and then set about guessing/estimating the parameter values for the rest of the model, but as you might have already suspected from last time, we can use Python, Statsmodels and the Poisson GLM to do this work for us!\n",
    "\n",
    "We set about re-specifying the Production-Constrained model as a Poisson regression model in a similar way to how we did before. We need to take logs of the right-hand side of equation and assume that these are logarithmially linked to the Poisson distributed mean ($\\lambda_{ij}$) of the $T_{ij}$ variable. Equation 1 (above) then becomes:\n",
    "\n",
    "4 $$\\lambda_{ij} = \\exp( \\mu_{i} + \\alpha \\ln W_{j} - \\beta \\ln d_{ij} )$$\n",
    "\n",
    "In equation 4, $\\mu_{i}$ is the equivalent of the vector $A_{i}O_{i}$. In the Poisson regression approach we are taking to estimation it is simply a categorical variable that identifies each discrete origin zone (e.g. by name or by zone code). For instance in the case of Barking and Dagenham we wouldn't pass the count of origin flows (5675), we would simply pass the variable that identifies that zone, perhaps 'Barking and Dagenham' (using 'Orig'), '00AB' (using 'OrigCode'), or 'E09000002' (using 'OrigNewCode').\n",
    "\n",
    "Finally, in Python (and R, actually) we specify the regression with the tag '-1' at the end of the equation. This is because we don't have a constant (like $k$) in the constrained spatial interaction model, and as such we don't want to estimate an intercept. If we didn't remove the intercept the model would set the $\\mu$ value for an arbitrary zone to be the intercept, and then the $\\mu$ values for all other zones would be relative to that first zone. By 'removing' the intercept with the '-1' we are actually setting the intercept to be 0, and hence each estiamted $mu_{i}$ value is relative to 0, making things easier for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Total</td>      <th>  No. Observations:  </th>  <td>    42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -14551.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 05 Feb 2018</td> <th>  Deviance:          </th> <td>  28788.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>12:31:14</td>     <th>  Pearson chi2:      </th> <td>2.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000001]</th> <td>    4.7076</td> <td>    0.119</td> <td>   39.458</td> <td> 0.000</td> <td>    4.474</td> <td>    4.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000002]</th> <td>    7.9961</td> <td>    0.114</td> <td>   70.267</td> <td> 0.000</td> <td>    7.773</td> <td>    8.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000003]</th> <td>    8.9812</td> <td>    0.111</td> <td>   81.058</td> <td> 0.000</td> <td>    8.764</td> <td>    9.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000004]</th> <td>    8.9571</td> <td>    0.113</td> <td>   79.443</td> <td> 0.000</td> <td>    8.736</td> <td>    9.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000005]</th> <td>    8.4777</td> <td>    0.111</td> <td>   76.709</td> <td> 0.000</td> <td>    8.261</td> <td>    8.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000006]</th> <td>    9.4865</td> <td>    0.114</td> <td>   83.016</td> <td> 0.000</td> <td>    9.262</td> <td>    9.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OrigNewCode[E09000007]</th> <td>    6.9794</td> <td>    0.110</td> <td>   63.635</td> <td> 0.000</td> <td>    6.764</td> <td>    7.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_wj2_destsal</th>        <td>    2.0471</td> <td>    0.010</td> <td>  201.778</td> <td> 0.000</td> <td>    2.027</td> <td>    2.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_dist</th>               <td>   -2.2423</td> <td>    0.011</td> <td> -197.074</td> <td> 0.000</td> <td>   -2.265</td> <td>   -2.220</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Total   No. Observations:                   42\n",
       "Model:                            GLM   Df Residuals:                       33\n",
       "Model Family:                 Poisson   Df Model:                            8\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -14551.\n",
       "Date:                Mon, 05 Feb 2018   Deviance:                       28788.\n",
       "Time:                        12:31:14   Pearson chi2:                 2.84e+04\n",
       "No. Iterations:                     8                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "OrigNewCode[E09000001]     4.7076      0.119     39.458      0.000       4.474       4.941\n",
       "OrigNewCode[E09000002]     7.9961      0.114     70.267      0.000       7.773       8.219\n",
       "OrigNewCode[E09000003]     8.9812      0.111     81.058      0.000       8.764       9.198\n",
       "OrigNewCode[E09000004]     8.9571      0.113     79.443      0.000       8.736       9.178\n",
       "OrigNewCode[E09000005]     8.4777      0.111     76.709      0.000       8.261       8.694\n",
       "OrigNewCode[E09000006]     9.4865      0.114     83.016      0.000       9.262       9.710\n",
       "OrigNewCode[E09000007]     6.9794      0.110     63.635      0.000       6.764       7.194\n",
       "log_wj2_destsal            2.0471      0.010    201.778      0.000       2.027       2.067\n",
       "log_dist                  -2.2423      0.011   -197.074      0.000      -2.265      -2.220\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a production constrained SIM using a Poisson GLM.\n",
    "# We'll do this using statsmodels, and the formula approach.\n",
    "# Here we're just using the 7 borough sub sample of data.\n",
    "# First take logs of the relevant fields\n",
    "cdatasub = cdatasub.assign(log_wj2_destsal = lambda x: np.log(x['wj2_destsal']))\n",
    "cdatasub = cdatasub.assign(log_dist = lambda x: np.log(x['dist']))\n",
    "\n",
    "# Here we specify a model with no intercept (given by the -1 in the formula)\n",
    "# In practice this means that all AiOis are estimated against an intercept of zero.\n",
    "# Including the interval would mean setting the first borough in OrigNewCode to the intercept\n",
    "# and interpreting all other categories in relation to that, which is less useful but would still work.\n",
    "formula = \"Total ~ OrigNewCode + log_wj2_destsal + log_dist -1\"\n",
    "prodSim = smf.glm(formula=formula, data = cdatasub, family = sm.families.Poisson()).fit()\n",
    "prodSim.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we have from this model?\n",
    "\n",
    "The $\\alpha$ parameter related to destination attractiveness is 2.0471\n",
    "\n",
    "The $\\beta$ distance decay parameter is -2.2423\n",
    "\n",
    "The 'coef' for each origin (given here as OrigNewCode[_code_]) is the logged $A_{i}O_{i}$ value for that origin.\n",
    "\n",
    "# 2.1 Model Estimates\n",
    "\n",
    "Now at this point you will be wanting to know what affect the constraints have had on the estimates produced by the model, so let’s plug the parameters back into Equation 4 and take a look.\n",
    "\n",
    "First we need some $O_{i}$ and $D_{j}$ columns to store the total in and out flows. We can do this by grouping the dataframe by the Origin and Destination codes, and summing up the 'Total' flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create some Oi and Dj columns in the dataframe and store row and column totals in them:\n",
    "# First get the origin sums and rename the column created\n",
    "O_i = cdatasub.groupby('OrigNewCode')['Total'].sum().to_frame()\n",
    "O_i.rename(columns = {'Total':'O_i'}, inplace=True)\n",
    "# Now get the destination sums\n",
    "D_j = cdatasub.groupby('DestNewCode')['Total'].sum().to_frame()\n",
    "D_j.rename(columns = {'Total':'D_j'}, inplace=True)\n",
    "\n",
    "# Merge in O_i\n",
    "cdatasub = cdatasub.merge(O_i,left_on='OrigNewCode',right_index=True)\n",
    "\n",
    "# Merge in D_j\n",
    "cdatasub = cdatasub.merge(D_j,left_on='DestNewCode',right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get our $\\mu$ values out, this is slightly tricky because in order to merge the values back into the dataframe we need the zonecode (e.g. E09000001) and not the model output (e.g. OrigNewCode[E09000001]).\n",
    "\n",
    "Dr. Dennett uses a regular expression (regex) approach, which I have mimiced below, however it's probably overkill to be honest, and it might not always work depending on the specific patterns present, so there's also a much simpler string indexing approach below too. The string index approach works by removing a given number of the first and last characters in the string and should be straightforward to reproduce with differently named variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig</th>\n",
       "      <th>OrigCode</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DestCode</th>\n",
       "      <th>Total</th>\n",
       "      <th>WorksFromHome</th>\n",
       "      <th>Underground</th>\n",
       "      <th>Train</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Taxi</th>\n",
       "      <th>...</th>\n",
       "      <th>wj1_destpop</th>\n",
       "      <th>wj2_destsal</th>\n",
       "      <th>dist</th>\n",
       "      <th>TotalNoIntra</th>\n",
       "      <th>offset</th>\n",
       "      <th>log_wj2_destsal</th>\n",
       "      <th>log_dist</th>\n",
       "      <th>O_i</th>\n",
       "      <th>D_j</th>\n",
       "      <th>mu_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>00AB</td>\n",
       "      <td>City of London</td>\n",
       "      <td>00AA</td>\n",
       "      <td>3641</td>\n",
       "      <td>0</td>\n",
       "      <td>1444</td>\n",
       "      <td>1788</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12000</td>\n",
       "      <td>38300</td>\n",
       "      <td>16021.038518</td>\n",
       "      <td>3641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.553205</td>\n",
       "      <td>9.681658</td>\n",
       "      <td>5675</td>\n",
       "      <td>40725</td>\n",
       "      <td>7.996147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>00AB</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>00AC</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>159000</td>\n",
       "      <td>18700</td>\n",
       "      <td>25075.424943</td>\n",
       "      <td>194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.836279</td>\n",
       "      <td>10.129644</td>\n",
       "      <td>5675</td>\n",
       "      <td>8122</td>\n",
       "      <td>7.996147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>00AB</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>00AD</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>112000</td>\n",
       "      <td>18300</td>\n",
       "      <td>9629.985305</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.814656</td>\n",
       "      <td>9.172637</td>\n",
       "      <td>5675</td>\n",
       "      <td>3389</td>\n",
       "      <td>7.996147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>00AB</td>\n",
       "      <td>Brent</td>\n",
       "      <td>00AE</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>127000</td>\n",
       "      <td>16500</td>\n",
       "      <td>27872.037104</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.711116</td>\n",
       "      <td>10.235379</td>\n",
       "      <td>5675</td>\n",
       "      <td>7356</td>\n",
       "      <td>7.996147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>00AB</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>00AF</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>164000</td>\n",
       "      <td>19100</td>\n",
       "      <td>20102.098077</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.857444</td>\n",
       "      <td>9.908579</td>\n",
       "      <td>5675</td>\n",
       "      <td>5266</td>\n",
       "      <td>7.996147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Orig OrigCode            Dest DestCode  Total  \\\n",
       "1    Barking and Dagenham     00AB  City of London     00AA   3641   \n",
       "67   Barking and Dagenham     00AB          Barnet     00AC    194   \n",
       "100  Barking and Dagenham     00AB          Bexley     00AD     96   \n",
       "133  Barking and Dagenham     00AB           Brent     00AE    178   \n",
       "166  Barking and Dagenham     00AB         Bromley     00AF     66   \n",
       "\n",
       "     WorksFromHome  Underground  Train  Bus  Taxi    ...     wj1_destpop  \\\n",
       "1                0         1444   1788   55     0    ...           12000   \n",
       "67               0           29     28    8     0    ...          159000   \n",
       "100              0            6      6    4     0    ...          112000   \n",
       "133              0           47     29    3     0    ...          127000   \n",
       "166              0            7     10    0     0    ...          164000   \n",
       "\n",
       "     wj2_destsal          dist  TotalNoIntra  offset  log_wj2_destsal  \\\n",
       "1          38300  16021.038518          3641     1.0        10.553205   \n",
       "67         18700  25075.424943           194     1.0         9.836279   \n",
       "100        18300   9629.985305            96     1.0         9.814656   \n",
       "133        16500  27872.037104           178     1.0         9.711116   \n",
       "166        19100  20102.098077            66     1.0         9.857444   \n",
       "\n",
       "      log_dist   O_i    D_j      mu_i  \n",
       "1     9.681658  5675  40725  7.996147  \n",
       "67   10.129644  5675   8122  7.996147  \n",
       "100   9.172637  5675   3389  7.996147  \n",
       "133  10.235379  5675   7356  7.996147  \n",
       "166   9.908579  5675   5266  7.996147  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same with the prodSim parameter estimates, first create a dataframe of \n",
    "mu_i = prodSim.params.to_frame()\n",
    "\n",
    "# Rename index values associated with geographies so I can merge the values with cdatasub\n",
    "\n",
    "# This approach uses a regex pattern that replaces all values with '' unless they are in the set E0123456789\n",
    "mu_i.rename(index = dict(zip(mu_i.index[0:-2].values, mu_i.index[0:-2].str.replace(r'[^E0123456789]','').values)),inplace=True)\n",
    "# An easier approach is to simply subset the strings using a list comprehension.\n",
    "#mu_i.rename(index = dict(zip(mu_i.index[:-2].values,[x[12:-1] for x in mu_i.index[:-2].values])))\n",
    "\n",
    "# Set column name to mu_I\n",
    "mu_i.rename(columns = {0:'mu_i'}, inplace=True)\n",
    "\n",
    "# Now merge\n",
    "cdatasub = cdatasub.merge(mu_i, left_on='OrigNewCode',right_index=True)\n",
    "cdatasub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can grab the alpha and beta parameters from the prodSim object (the Poisson regression model we ran) and plug everything into the Equation to create a new estimate of flows called 'prodsimest'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates into variables\n",
    "alpha = prodSim.params[7]\n",
    "beta = prodSim.params[8]\n",
    "\n",
    "# Now generate some rounded estimates by \n",
    "cdatasub['prodsimest'] = np.round(np.exp(cdatasub['mu_i'] + alpha * cdatasub['log_wj2_destsal'] + beta * cdatasub['log_dist']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Accessing the model output\n",
    "\n",
    "So what do the outputs from our Production Constrained Model look like? How has the goodness-of-fit improved and how can we start to use this a bit like a retail model and assess the likely impacts of changing destination attractiveness etc.?\n",
    "\n",
    "## 2.2.1 The flow matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>5674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6905.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>7550.0</td>\n",
       "      <td>9821.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>3755.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>5868.0</td>\n",
       "      <td>14687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>215.0</td>\n",
       "      <td>5392.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>5663.0</td>\n",
       "      <td>6765.0</td>\n",
       "      <td>18509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>1224.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>99.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9703.0</td>\n",
       "      <td>11768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5760.0</td>\n",
       "      <td>7505.0</td>\n",
       "      <td>8104.0</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>15914.0</td>\n",
       "      <td>43131.0</td>\n",
       "      <td>93802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   225.0  1843.0   138.0    386.0   \n",
       "Barnet                               450.0     0.0   388.0  6905.0    348.0   \n",
       "Bexley                              3755.0   396.0     0.0   295.0   3557.0   \n",
       "Brent                                215.0  5392.0   226.0     0.0    248.0   \n",
       "Bromley                             1224.0   553.0  5533.0   503.0      0.0   \n",
       "Camden                                99.0   907.0    96.0   871.0     92.0   \n",
       "City of London                        17.0    32.0    18.0    28.0     17.0   \n",
       "All                                 5760.0  7505.0  8104.0  8740.0   4648.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    412.0          2670.0   5674.0  \n",
       "Barnet                 7550.0          9821.0  25462.0  \n",
       "Bexley                  816.0          5868.0  14687.0  \n",
       "Brent                  5663.0          6765.0  18509.0  \n",
       "Bromley                1214.0          8304.0  17331.0  \n",
       "Camden                    0.0          9703.0  11768.0  \n",
       "City of London          259.0             0.0    371.0  \n",
       "All                   15914.0         43131.0  93802.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now look at the matrix of flows\n",
    "pd.pivot_table(cdatasub,values='prodsimest',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compared to the original observed flows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5467.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12080.0</td>\n",
       "      <td>7709.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>362.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>40.0</td>\n",
       "      <td>6124.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8105.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>134.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3199.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>9855.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   194.0    96.0   178.0     66.0   \n",
       "Barnet                                96.0     0.0    34.0  5467.0     76.0   \n",
       "Bexley                               362.0   132.0     0.0   144.0   4998.0   \n",
       "Brent                                 40.0  6124.0    28.0     0.0     66.0   \n",
       "Bromley                              134.0   162.0  3199.0   201.0      0.0   \n",
       "Camden                                36.0  1496.0    32.0  1350.0     60.0   \n",
       "City of London                         6.0    14.0     0.0    16.0      0.0   \n",
       "All                                  674.0  8122.0  3389.0  7356.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1500.0          3641.0   5675.0  \n",
       "Barnet                12080.0          7709.0  25462.0  \n",
       "Bexley                 2470.0          6580.0  14686.0  \n",
       "Brent                  8105.0          4145.0  18508.0  \n",
       "Bromley                3780.0          9855.0  17331.0  \n",
       "Camden                    0.0          8795.0  11769.0  \n",
       "City of London          335.0             0.0    371.0  \n",
       "All                   28270.0         40725.0  93802.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compared to the original flows - sum across columns to see constraints working.\n",
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is very easy to see the origin constraints working. The sum across all destinations (columns) for each origin (rows) is the same (subject to rounding - note Barking and Dagenham, Bexley, Brent and Camden are all off by 1) in the predicted trips matrix and the observed trips matrix. Essentially, $\\sum_{j}T_{ij} = \\sum_{j}\\lambda_{ij} = O_{i}$ more or less holds, but the same is not true for destinations summing for all origins, for instance, Barking and Dagenham is predicted many more trips than in reality, and Camden is predicted far fewer. In this sense, $\\sum_{i}T_{ij} = \\sum_{i}\\lambda_{ij} = D_{j}$\n",
    "\n",
    "## 2.2.2 How does the attraction constrained model perform?\n",
    "\n",
    "NB I've copied over the same function that we used in the last practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared = 0.817447925947\n",
      "RMSE = 1383.01497771\n"
     ]
    }
   ],
   "source": [
    "# Goodness of fit (functions borrowed from previous practical)\n",
    "\n",
    "# Function to compute R^2\n",
    "def calcR2(obs,est):\n",
    "    return np.power(np.corrcoef(obs,est),2.0)[0][1]\n",
    "\n",
    "# Function to compute RMSE\n",
    "def calcRMSE(obs,est):\n",
    "    return np.sqrt((np.power((obs - est),2.0)).mean())\n",
    "\n",
    "print \"R squared =\", calcR2(cdatasub['Total'],cdatasub['prodsimest'])\n",
    "print \"RMSE =\", calcRMSE(cdatasub['Total'],cdatasub['prodsimest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly by constraining our model estimates to known origin totals, the fit of the model has improved quite considerably - from around 0.67 in the unconstrained model to around 0.82 in this model. The RMSE has also dropped quite noticably.\n",
    "\n",
    "## 2.2.3 A 'what if...' scenario\n",
    "\n",
    "Now that we have calibrated our parameters and produced some estimates, we can start to play around with some what-if scenarios.\n",
    "\n",
    "In a 'what if' scenario, we make the assumption that the parameters for alpha and beta are universal (that is - they don't change subject to circumstance), and we use this model as a basis for exploring different scenarios by changing other data in the model, such as the observed $W_{j}$ values, here median income at the destination (the attractive force), or the cost of travelling between two places. As we're using straight-line distance to equal cost here it doesn't make a great deal of sense to change that in our model though!\n",
    "\n",
    "So, by way of example - What if the government invested loads of money into a new Car Plant in Barking and Dagenham and as a result, average wages increased from a mere £16,200 to £25,000. A far fetched scenario, but one that could make a good experiment.\n",
    "\n",
    "First create create a new variable with these altered salaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's try a what if scenario\n",
    "# The scenario says if destination median income is 16200, set the new value to be 25000, otherwise leave it the same.\n",
    "cdatasub = cdatasub.assign(wj3_destsalScenario = np.where(cdatasub['wj2_destsal'] == 16200, 25000,cdatasub['wj2_destsal']))\n",
    "# Take the log of the new variable\n",
    "cdatasub = cdatasub.assign(log_wj3_destsalScenario = lambda x: np.log(x['wj3_destsalScenario']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s plug these new values into the model and see how this changes the flows in the system…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>5674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6905.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>7550.0</td>\n",
       "      <td>9821.0</td>\n",
       "      <td>26105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>9126.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>5868.0</td>\n",
       "      <td>20058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>521.0</td>\n",
       "      <td>5392.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>5663.0</td>\n",
       "      <td>6765.0</td>\n",
       "      <td>18815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>2975.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>19082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>240.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9703.0</td>\n",
       "      <td>11909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>13997.0</td>\n",
       "      <td>7505.0</td>\n",
       "      <td>8104.0</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>15914.0</td>\n",
       "      <td>43131.0</td>\n",
       "      <td>102039.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   225.0  1843.0   138.0    386.0   \n",
       "Barnet                              1093.0     0.0   388.0  6905.0    348.0   \n",
       "Bexley                              9126.0   396.0     0.0   295.0   3557.0   \n",
       "Brent                                521.0  5392.0   226.0     0.0    248.0   \n",
       "Bromley                             2975.0   553.0  5533.0   503.0      0.0   \n",
       "Camden                               240.0   907.0    96.0   871.0     92.0   \n",
       "City of London                        42.0    32.0    18.0    28.0     17.0   \n",
       "All                                13997.0  7505.0  8104.0  8740.0   4648.0   \n",
       "\n",
       "Dest                   Camden  City of London       All  \n",
       "Orig                                                     \n",
       "Barking and Dagenham    412.0          2670.0    5674.0  \n",
       "Barnet                 7550.0          9821.0   26105.0  \n",
       "Bexley                  816.0          5868.0   20058.0  \n",
       "Brent                  5663.0          6765.0   18815.0  \n",
       "Bromley                1214.0          8304.0   19082.0  \n",
       "Camden                    0.0          9703.0   11909.0  \n",
       "City of London          259.0             0.0     396.0  \n",
       "All                   15914.0         43131.0  102039.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now plug these new values into the model and see what happens\n",
    "cdatasub['prodsimest_scenario'] = np.round(np.exp(cdatasub['mu_i'] + alpha * cdatasub['log_wj3_destsalScenario'] + beta * cdatasub['log_dist']))\n",
    "# Here's the matrix\n",
    "pd.pivot_table(cdatasub,values='prodsimest_scenario',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that by increasing the average salary in Barking and Dagenham, we’ve increased flows into Barking and Dagenham, but have not reduced the flows into other zones - the original constraints are still working on the other zones. As a result our new count of total flows (102,039) is larger than the observed (93,802). \n",
    "\n",
    "One way to resolve this issue and reconstrain the total, now that we have calibrated our parameters, is to return to the multiplicative model in Equation 1 and run this model after calculating our own $A_{i}$ balancing factors.\n",
    "\n",
    "Let's first look at how to calculate the $A_{i}$ values for the original (non-scenario) model, using the $\\alpha$ and $\\beta$ values that we derived with the Poisson regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>5674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>6905.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>7550.0</td>\n",
       "      <td>9821.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>3755.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>5868.0</td>\n",
       "      <td>14687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>215.0</td>\n",
       "      <td>5392.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>5663.0</td>\n",
       "      <td>6765.0</td>\n",
       "      <td>18509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>1224.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>99.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9703.0</td>\n",
       "      <td>11768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5760.0</td>\n",
       "      <td>7505.0</td>\n",
       "      <td>8104.0</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>15914.0</td>\n",
       "      <td>43131.0</td>\n",
       "      <td>93802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   225.0  1843.0   138.0    386.0   \n",
       "Barnet                               450.0     0.0   388.0  6905.0    348.0   \n",
       "Bexley                              3755.0   396.0     0.0   295.0   3557.0   \n",
       "Brent                                215.0  5392.0   226.0     0.0    248.0   \n",
       "Bromley                             1224.0   553.0  5533.0   503.0      0.0   \n",
       "Camden                                99.0   907.0    96.0   871.0     92.0   \n",
       "City of London                        17.0    32.0    18.0    28.0     17.0   \n",
       "All                                 5760.0  7505.0  8104.0  8740.0   4648.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    412.0          2670.0   5674.0  \n",
       "Barnet                 7550.0          9821.0  25462.0  \n",
       "Bexley                  816.0          5868.0  14687.0  \n",
       "Brent                  5663.0          6765.0  18509.0  \n",
       "Bromley                1214.0          8304.0  17331.0  \n",
       "Camden                    0.0          9703.0  11768.0  \n",
       "City of London          259.0             0.0    371.0  \n",
       "All                   15914.0         43131.0  93802.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the total flows are now wrong, we need to recalculate the balancing factors.\n",
    "# Let's do it first for the original estimates and see if we get the same results.\n",
    "\n",
    "# Calculate some wj^alpha and dij^beta values\n",
    "wj2_alpha = np.power(cdatasub['wj2_destsal'],alpha)\n",
    "dist_beta = np.power(cdatasub['dist'],beta)\n",
    "\n",
    "# Calculate the first stage of the Ai values\n",
    "cdatasub = cdatasub.assign(Ai1 = wj2_alpha*dist_beta)\n",
    "\n",
    "# Now sum over all js\n",
    "A_i = cdatasub.groupby('OrigNewCode')['Ai1'].sum().to_frame()\n",
    "A_i.rename(columns = {'Ai1':'A_i'}, inplace=True)\n",
    "\n",
    "# Merge in the inverse of A_i\n",
    "cdatasub = cdatasub.merge(1.0/A_i,left_on='OrigNewCode',right_index=True)\n",
    "\n",
    "# Now make the flow estimates\n",
    "cdatasub['prodsimest_Ais'] = np.round(cdatasub['A_i'] * cdatasub['O_i'] * wj2_alpha * dist_beta)\n",
    "# Here's the matrix, it works!\n",
    "pd.pivot_table(cdatasub,values='prodsimest_Ais',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is it for calculating your $A_{i}$ values. The flow matrix above is the same as the original model estimates!\n",
    "\n",
    "In fact, we can demonstrate that the output $\\mu_{i}$ we get from the Poisson regression is simply $\\log(A_{i}O_{i})$ or vice versa by comparing the two quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the multiplication of A_i and O_i above is simply the exponential of mu_i from the poisson model!\n",
    "# I've truncated to 8 decimal places because a slight difference creeps from 9 d.p. due to computation.\n",
    "# NB This equality prints true if all values are the same i.e. A_i*O_i == exp(mu_i) for all i\n",
    "(np.round(cdatasub['A_i'] * cdatasub['O_i'],8) == np.round(np.exp(cdatasub['mu_i']),8)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the same approach can be applied to rebalancing our scenario data, under the assumption that $\\alpha$ and $\\beta$ are universal. Remember, though, that you will need to recalculate $A_{i}$ each time you want to create a new set of estimates based on a new scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>5674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>1066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>7364.0</td>\n",
       "      <td>9579.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>6682.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>4296.0</td>\n",
       "      <td>14685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>513.0</td>\n",
       "      <td>5304.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>6654.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>2702.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>5025.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>17330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>238.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9588.0</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>11240.0</td>\n",
       "      <td>7248.0</td>\n",
       "      <td>7580.0</td>\n",
       "      <td>8433.0</td>\n",
       "      <td>3681.0</td>\n",
       "      <td>15289.0</td>\n",
       "      <td>40329.0</td>\n",
       "      <td>93800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   225.0  1843.0   138.0    386.0   \n",
       "Barnet                              1066.0     0.0   378.0  6735.0    340.0   \n",
       "Bexley                              6682.0   290.0     0.0   216.0   2604.0   \n",
       "Brent                                513.0  5304.0   222.0     0.0    244.0   \n",
       "Bromley                             2702.0   502.0  5025.0   457.0      0.0   \n",
       "Camden                               238.0   897.0    95.0   861.0     91.0   \n",
       "City of London                        39.0    30.0    17.0    26.0     16.0   \n",
       "All                                11240.0  7248.0  7580.0  8433.0   3681.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    412.0          2670.0   5674.0  \n",
       "Barnet                 7364.0          9579.0  25462.0  \n",
       "Bexley                  597.0          4296.0  14685.0  \n",
       "Brent                  5571.0          6654.0  18508.0  \n",
       "Bromley                1102.0          7542.0  17330.0  \n",
       "Camden                    0.0          9588.0  11770.0  \n",
       "City of London          243.0             0.0    371.0  \n",
       "All                   15289.0         40329.0  93800.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's rebalance the estimates for our scenario.\n",
    "\n",
    "# Calculate some new wj^alpha values\n",
    "wj3_alpha = np.power(cdatasub['wj3_destsalScenario'],alpha)\n",
    "\n",
    "# Calculate the first stage of the Ai values\n",
    "cdatasub = cdatasub.assign(Ai1 = wj3_alpha*dist_beta)\n",
    "\n",
    "# Now sum over all js\n",
    "A_i = cdatasub.groupby('OrigNewCode')['Ai1'].sum().to_frame()\n",
    "A_i.rename(columns = {'Ai1':'A_i'}, inplace=True)\n",
    "\n",
    "# Drop previous A_i column\n",
    "cdatasub.drop(['A_i'], axis = 1, inplace = True)\n",
    "# Merge in the inverse of A_i\n",
    "cdatasub = cdatasub.merge(1.0/A_i,left_on='OrigNewCode',right_index=True)\n",
    "\n",
    "# Now make the scenario flow estimates\n",
    "cdatasub['prodsimest_scenario'] = np.round(cdatasub['A_i'] * cdatasub['O_i'] * wj3_alpha * dist_beta)\n",
    "# Here's the matrix, it works (subject to a couple of rounding errors)!\n",
    "pd.pivot_table(cdatasub,values='prodsimest_scenario',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, subject to rounding errors, we have rebalanced the scenario to the original origin and total constraints.\n",
    "\n",
    "There are a number of things to note here. Firstly, we see flows into Barking and Dagenham have virtually doubled, while flows into other Boroughs have reduced.\n",
    "\n",
    "Secondly, Barking and Dagenham was a poor estimate anyway - the model was very much over-estimating flows into this Borough. Increasing the median income in this borough has significantly increased flows, indicating that there are probably lots of other things that might be discouraging people from working in this borough.\n",
    "\n",
    "Thirdly, Our origin constraints are now holding again.\n",
    "\n",
    "# 3. Attraction Constrained Model\n",
    "\n",
    "The attraction constrained Model is virtually the same as the production constrained model:\n",
    "\n",
    "5 $$T_{ij} = D_{j}B_{j}V_{i}^{\\mu}d_{ij}^{-\\beta}$$\n",
    "where\n",
    "\n",
    "6 $$D_{j} = \\sum_{i}T_{ij}$$\n",
    "and\n",
    "\n",
    "7 $$B_{j} = \\frac{i}{\\sum_{i}V_{i}^{\\mu}d_{ij}^{-\\beta}}$$\n",
    "or framed as a Poisson regression:\n",
    "\n",
    "8 $$\\lambda_{ij} = \\exp(\\mu \\ln V_{i} + \\alpha_{i} - \\beta \\ln d_{ij})$$\n",
    "\n",
    "In which $\\alpha_{i}$ represents the $D_{j}B_{j}$ part of the model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Total</td>      <th>  No. Observations:  </th>  <td>    42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -11902.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 05 Feb 2018</td> <th>  Deviance:          </th> <td>  23489.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>15:02:10</td>     <th>  Pearson chi2:      </th> <td>2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000001]</th> <td>    1.9189</td> <td>    0.135</td> <td>   14.251</td> <td> 0.000</td> <td>    1.655</td> <td>    2.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000002]</th> <td>   -1.6652</td> <td>    0.141</td> <td>  -11.795</td> <td> 0.000</td> <td>   -1.942</td> <td>   -1.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000003]</th> <td>    0.6945</td> <td>    0.134</td> <td>    5.169</td> <td> 0.000</td> <td>    0.431</td> <td>    0.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000004]</th> <td>   -0.0065</td> <td>    0.137</td> <td>   -0.047</td> <td> 0.962</td> <td>   -0.275</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000005]</th> <td>    0.3785</td> <td>    0.136</td> <td>    2.791</td> <td> 0.005</td> <td>    0.113</td> <td>    0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000006]</th> <td>    0.8223</td> <td>    0.135</td> <td>    6.073</td> <td> 0.000</td> <td>    0.557</td> <td>    1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DestNewCode[E09000007]</th> <td>    1.6193</td> <td>    0.135</td> <td>   11.955</td> <td> 0.000</td> <td>    1.354</td> <td>    1.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_vi1_origpop</th>        <td>    1.5587</td> <td>    0.011</td> <td>  137.030</td> <td> 0.000</td> <td>    1.536</td> <td>    1.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_dist</th>               <td>   -1.2037</td> <td>    0.007</td> <td> -171.500</td> <td> 0.000</td> <td>   -1.217</td> <td>   -1.190</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Total   No. Observations:                   42\n",
       "Model:                            GLM   Df Residuals:                       33\n",
       "Model Family:                 Poisson   Df Model:                            8\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -11902.\n",
       "Date:                Mon, 05 Feb 2018   Deviance:                       23489.\n",
       "Time:                        15:02:10   Pearson chi2:                 2.26e+04\n",
       "No. Iterations:                     7                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "DestNewCode[E09000001]     1.9189      0.135     14.251      0.000       1.655       2.183\n",
       "DestNewCode[E09000002]    -1.6652      0.141    -11.795      0.000      -1.942      -1.388\n",
       "DestNewCode[E09000003]     0.6945      0.134      5.169      0.000       0.431       0.958\n",
       "DestNewCode[E09000004]    -0.0065      0.137     -0.047      0.962      -0.275       0.262\n",
       "DestNewCode[E09000005]     0.3785      0.136      2.791      0.005       0.113       0.644\n",
       "DestNewCode[E09000006]     0.8223      0.135      6.073      0.000       0.557       1.088\n",
       "DestNewCode[E09000007]     1.6193      0.135     11.955      0.000       1.354       1.885\n",
       "log_vi1_origpop            1.5587      0.011    137.030      0.000       1.536       1.581\n",
       "log_dist                  -1.2037      0.007   -171.500      0.000      -1.217      -1.190\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for a quick attraction constrained model\n",
    "cdatasub = cdatasub.assign(log_vi1_origpop = lambda x: np.log(x['vi1_origpop']))\n",
    "\n",
    "formula = \"Total ~ DestNewCode + log_vi1_origpop + log_dist -1\"\n",
    "attrSim = smf.glm(formula=formula, data = cdatasub, family = sm.families.Poisson()).fit()\n",
    "attrSim.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine how the constraints hold for destinations this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>3525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>4021.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11940.0</td>\n",
       "      <td>8986.0</td>\n",
       "      <td>26665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>225.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>2121.0</td>\n",
       "      <td>3998.0</td>\n",
       "      <td>9580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>76.0</td>\n",
       "      <td>3886.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>9445.0</td>\n",
       "      <td>6790.0</td>\n",
       "      <td>21382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>168.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>6571.0</td>\n",
       "      <td>13836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>79.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12890.0</td>\n",
       "      <td>18328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>675.0</td>\n",
       "      <td>8123.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7357.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28268.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   255.0   401.0   164.0    379.0   \n",
       "Barnet                               123.0     0.0   521.0  4021.0   1074.0   \n",
       "Bexley                               225.0   608.0     0.0   435.0   2193.0   \n",
       "Brent                                 76.0  3886.0   360.0     0.0    825.0   \n",
       "Bromley                              168.0   992.0  1735.0   789.0      0.0   \n",
       "Camden                                79.0  2335.0   355.0  1911.0    758.0   \n",
       "City of London                         4.0    47.0    18.0    37.0     37.0   \n",
       "All                                  675.0  8123.0  3390.0  7357.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    836.0          1490.0   3525.0  \n",
       "Barnet                11940.0          8986.0  26665.0  \n",
       "Bexley                 2121.0          3998.0   9580.0  \n",
       "Brent                  9445.0          6790.0  21382.0  \n",
       "Bromley                3581.0          6571.0  13836.0  \n",
       "Camden                    0.0         12890.0  18328.0  \n",
       "City of London          345.0             0.0    488.0  \n",
       "All                   28268.0         40725.0  93804.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the estimates - note I've done it the easy way here!\n",
    "cdatasub['attrsimfitted'] = np.round(attrSim.predict())\n",
    "# Here's the matrix\n",
    "pd.pivot_table(cdatasub,values='attrsimfitted',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5467.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12080.0</td>\n",
       "      <td>7709.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>362.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>40.0</td>\n",
       "      <td>6124.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8105.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>134.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3199.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>9855.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93802.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   194.0    96.0   178.0     66.0   \n",
       "Barnet                                96.0     0.0    34.0  5467.0     76.0   \n",
       "Bexley                               362.0   132.0     0.0   144.0   4998.0   \n",
       "Brent                                 40.0  6124.0    28.0     0.0     66.0   \n",
       "Bromley                              134.0   162.0  3199.0   201.0      0.0   \n",
       "Camden                                36.0  1496.0    32.0  1350.0     60.0   \n",
       "City of London                         6.0    14.0     0.0    16.0      0.0   \n",
       "All                                  674.0  8122.0  3389.0  7356.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1500.0          3641.0   5675.0  \n",
       "Barnet                12080.0          7709.0  25462.0  \n",
       "Bexley                 2470.0          6580.0  14686.0  \n",
       "Brent                  8105.0          4145.0  18508.0  \n",
       "Bromley                3780.0          9855.0  17331.0  \n",
       "Camden                    0.0          8795.0  11769.0  \n",
       "City of London          335.0             0.0    371.0  \n",
       "All                   28270.0         40725.0  93802.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compared to the original flows - sum down rows to see constraints working.\n",
    "cdatasubmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can test the goodness-of-fit in exactly the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared = 0.844315885864\n",
      "RMSE = 1310.21563111\n"
     ]
    }
   ],
   "source": [
    "# Finally, the goodness of fit for the attraction constrained model\n",
    "print \"R squared =\", calcR2(cdatasub['Total'],cdatasub['attrsimfitted'])\n",
    "print \"RMSE =\", calcRMSE(cdatasub['Total'],cdatasub['attrsimfitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that’s where I’ll leave singly constrained models for now. There are, of course, plenty of things you could try out. For example:\n",
    "\n",
    "1. You could try mapping the coefficients or the residual values from the model to see if there is any patterning in either the over or under prediction of flows.\n",
    "2. You could try running your own version of a LUTI model by first calibrating the model parameters and plugging these into a multiplicative version of the model, adjusting the destination constraints to see which origins are likely to generate more trips.\n",
    "\n",
    "# 4. Doubly Constrained Model\n",
    "\n",
    "Now, the model in the family you have all been waiting for - the big boss, the daddy, the __doubly constrained model!__\n",
    "\n",
    "Let's begin with the formula:\n",
    "\n",
    "9 $$T_{ij} = A_{i}O_{i}B_{j}D_{j}d_{ij}^{-\\beta}$$\n",
    "where\n",
    "\n",
    "10 $$O_{i} = \\sum_{j}T_{ij}$$\n",
    "11 $$D_{j} = \\sum_{i}T_{ij}$$\n",
    "and\n",
    "\n",
    "12 $$A_{i} = \\frac{1}{\\sum_{j}B_{j}D_{j}d_{ij}^{-\\beta}}$$\n",
    "13 $$B_{j} = \\frac{1}{\\sum_{i}A_{i}O_{i}d_{ij}^{-\\beta}}$$\n",
    "\n",
    "Now, the astute will have noticed that the calculation of $A_{i}$ relies on knowing $B_{j}$ and the calculation of $B_{j}$ relies on knowing $A_{i}$. This is a potentially tricky situation, how can you calcualte either if both are unknown?\n",
    "\n",
    "Well, I wrestled with that for a while until I came across [this paper by Martyn Senior](http://journals.sagepub.com/doi/abs/10.1177/030913257900300218) where he sketches out a very useful algorithm for iteratively arriving at values for $A_{i}$ and $B_{j}$ by setting $B_{j}$ equal to 1 initially, and then iteratively refining the value of each until they are stable (that is they converge on a particular value).\n",
    "\n",
    "We will return to this later, but for now, we will once again use the awesome power of Python to deal with this difficulty for us!\n",
    "\n",
    "We can run the doubly constrained model in effectively the same way as we ran the singly constrained models:\n",
    "\n",
    "14 $$\\lambda_{ij} = \\exp(\\mu_{i} + \\alpha_{i} - \\beta \\ln d_{ij} )$$\n",
    "\n",
    "Or in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Total</td>      <th>  No. Observations:  </th>  <td>    42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -2802.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 05 Feb 2018</td> <th>  Deviance:          </th> <td>  5290.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>15:16:06</td>     <th>  Pearson chi2:      </th> <td>4.60e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barking and Dagenham]</th> <td>   28.1500</td> <td>    0.143</td> <td>  196.500</td> <td> 0.000</td> <td>   27.869</td> <td>   28.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barnet]</th>               <td>   28.5771</td> <td>    0.135</td> <td>  211.481</td> <td> 0.000</td> <td>   28.312</td> <td>   28.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bexley]</th>               <td>   29.1542</td> <td>    0.142</td> <td>  205.003</td> <td> 0.000</td> <td>   28.875</td> <td>   29.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Brent]</th>                <td>   27.9590</td> <td>    0.133</td> <td>  209.623</td> <td> 0.000</td> <td>   27.698</td> <td>   28.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bromley]</th>              <td>   29.7550</td> <td>    0.145</td> <td>  205.622</td> <td> 0.000</td> <td>   29.471</td> <td>   30.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Camden]</th>               <td>   26.7334</td> <td>    0.128</td> <td>  209.305</td> <td> 0.000</td> <td>   26.483</td> <td>   26.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[City of London]</th>       <td>   23.8944</td> <td>    0.140</td> <td>  171.051</td> <td> 0.000</td> <td>   23.621</td> <td>   24.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Barnet]</th>             <td>    2.9636</td> <td>    0.041</td> <td>   71.598</td> <td> 0.000</td> <td>    2.883</td> <td>    3.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bexley]</th>             <td>    1.4611</td> <td>    0.043</td> <td>   33.876</td> <td> 0.000</td> <td>    1.377</td> <td>    1.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Brent]</th>              <td>    2.3925</td> <td>    0.041</td> <td>   57.939</td> <td> 0.000</td> <td>    2.312</td> <td>    2.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bromley]</th>            <td>    2.6533</td> <td>    0.041</td> <td>   64.707</td> <td> 0.000</td> <td>    2.573</td> <td>    2.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Camden]</th>             <td>    3.5594</td> <td>    0.040</td> <td>   89.094</td> <td> 0.000</td> <td>    3.481</td> <td>    3.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.City of London]</th>     <td>    4.1095</td> <td>    0.040</td> <td>  103.336</td> <td> 0.000</td> <td>    4.032</td> <td>    4.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_dist</th>                   <td>   -2.5032</td> <td>    0.015</td> <td> -171.845</td> <td> 0.000</td> <td>   -2.532</td> <td>   -2.475</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Total   No. Observations:                   42\n",
       "Model:                            GLM   Df Residuals:                       28\n",
       "Model Family:                 Poisson   Df Model:                           13\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -2802.4\n",
       "Date:                Mon, 05 Feb 2018   Deviance:                       5290.3\n",
       "Time:                        15:16:06   Pearson chi2:                 4.60e+03\n",
       "No. Iterations:                     8                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Orig[Barking and Dagenham]    28.1500      0.143    196.500      0.000      27.869      28.431\n",
       "Orig[Barnet]                  28.5771      0.135    211.481      0.000      28.312      28.842\n",
       "Orig[Bexley]                  29.1542      0.142    205.003      0.000      28.875      29.433\n",
       "Orig[Brent]                   27.9590      0.133    209.623      0.000      27.698      28.220\n",
       "Orig[Bromley]                 29.7550      0.145    205.622      0.000      29.471      30.039\n",
       "Orig[Camden]                  26.7334      0.128    209.305      0.000      26.483      26.984\n",
       "Orig[City of London]          23.8944      0.140    171.051      0.000      23.621      24.168\n",
       "Dest[T.Barnet]                 2.9636      0.041     71.598      0.000       2.883       3.045\n",
       "Dest[T.Bexley]                 1.4611      0.043     33.876      0.000       1.377       1.546\n",
       "Dest[T.Brent]                  2.3925      0.041     57.939      0.000       2.312       2.473\n",
       "Dest[T.Bromley]                2.6533      0.041     64.707      0.000       2.573       2.734\n",
       "Dest[T.Camden]                 3.5594      0.040     89.094      0.000       3.481       3.638\n",
       "Dest[T.City of London]         4.1095      0.040    103.336      0.000       4.032       4.187\n",
       "log_dist                      -2.5032      0.015   -171.845      0.000      -2.532      -2.475\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the doubly constrained model!\n",
    "formula = \"Total ~ Orig + Dest + log_dist -1\"\n",
    "doubSim = smf.glm(formula=formula, data = cdatasub, family = sm.families.Poisson()).fit()\n",
    "doubSim.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the various flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>3055.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5542.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>12967.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>490.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>4492.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>6871.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5288.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>8893.0</td>\n",
       "      <td>4162.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>141.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>10226.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9736.0</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8123.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5267.0</td>\n",
       "      <td>28269.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   317.0   773.0   137.0    404.0   \n",
       "Barnet                                25.0     0.0    69.0  5542.0    184.0   \n",
       "Bexley                               490.0   554.0     0.0   301.0   4492.0   \n",
       "Brent                                 10.0  5288.0    36.0     0.0    119.0   \n",
       "Bromley                              141.0   813.0  2487.0   550.0      0.0   \n",
       "Camden                                 7.0  1131.0    22.0   813.0     61.0   \n",
       "City of London                         1.0    20.0     3.0    13.0      7.0   \n",
       "All                                  674.0  8123.0  3390.0  7356.0   5267.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    989.0          3055.0   5675.0  \n",
       "Barnet                12967.0          6675.0  25462.0  \n",
       "Bexley                 1978.0          6871.0  14686.0  \n",
       "Brent                  8893.0          4162.0  18508.0  \n",
       "Bromley                3114.0         10226.0  17331.0  \n",
       "Camden                    0.0          9736.0  11770.0  \n",
       "City of London          328.0             0.0    372.0  \n",
       "All                   28269.0         40725.0  93804.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the estimates\n",
    "cdatasub['doubsimfitted'] = np.round(doubSim.predict())\n",
    "# Here's the matrix\n",
    "pd.pivot_table(cdatasub,values='doubsimfitted',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared = 0.982471829461\n",
      "RMSE = 440.269560286\n"
     ]
    }
   ],
   "source": [
    "# Now, the goodness of fit for the doubly constrained model\n",
    "print \"R squared =\", calcR2(cdatasub['Total'],cdatasub['doubsimfitted'])\n",
    "print \"RMSE =\", calcRMSE(cdatasub['Total'],cdatasub['doubsimfitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the goodness of fit has shot up and we can clearly see the origin and destination constraints working, and for most sets of flows, the model is now producing some good estimates. However, there are still some errors in the flows, particularly for estimates between Barking and Dagenham and Bexley or Barnet and Camden.\n",
    "\n",
    "Is there anything more we can do? Yes, of course there is.\n",
    "\n",
    "# 4.1 Tweaking our Model\n",
    "## 4.1.1 Distance Decay\n",
    "\n",
    "Now, all of the way through these practicals, we have assumed that the distance decay parameter follows a negative power law. Well, it doesn’t need to.\n",
    "\n",
    "In [Wilson’s original paper](http://journals.sagepub.com/doi/abs/10.1068/a030001), he generalised the distance decay parameter to:\n",
    "\n",
    "$$f(d_{ij})$$\n",
    "\n",
    "Where $f$ represents some function of distance describing the rate at which the flow interactions change as distance changes. Lots of people have written about this, including [Taylor (1971)](http://onlinelibrary.wiley.com/doi/10.1111/j.1538-4632.1971.tb00364.x/full).\n",
    "\n",
    "For the inverse power law that we have been using is one possible function of distance, the other common one that is used is the negative exponential function:\n",
    "\n",
    "$$\\exp(-\\beta d_{ij})$$\n",
    "\n",
    "We can get a feel for how different distance decay parameters work by plotting some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFpCAYAAACmt+D8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEozCWUREJMH8fwBL75NQwPKqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdad02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's consider some model tweaks.\n",
    "# Starting with distance decay.\n",
    "# Let's graph so distance decay parameters to get a feel for how they work.\n",
    "xs = np.arange(1.0,20.0,0.25)\n",
    "# inverse square power\n",
    "y_inv_power = np.power(xs,-2)\n",
    "# negative exponential, beta = 0.3\n",
    "y_neg_exp_point3 = np.exp(-0.3*xs)\n",
    "\n",
    "# Now a plot.\n",
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(xs,y_inv_power, label = \"Inverse Power\")\n",
    "ax.plot(xs,y_neg_exp_point3, label = 'Negative Exponential')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see quite clearly that the inverse power function specified has a more rapid distance decay effect than the negative exponential function specified. It is important to note that this won't always be the case, as it depends on the values of $\\beta$ actually chosen.\n",
    "\n",
    "There is no hard and fast rule as to which function to pick, however some studies have suggested that square laws are good for short range interactions, while exponential models tend to be better for long range interactions. In real life, what this means is that if the observed interactions drop off very rapidly with distance, then they might be more likely to follow an inverse power law. This might be the case when looking at trips to the local convenience store by walking, for example. On the other hand, if the effect of distance is less severe (for example migration across the country for a new job) then the negative exponential funtion might be more appropriate.\n",
    "\n",
    "As [Tayor Oshan points out in his excellent Primer](http://openjournals.wu.ac.at/region/paper_175/175.html) what this means for our Poisson regression model is that we simply substitute $−\\beta \\ln d_{ij}$ for $−\\beta ⁡d_{ij}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Total</td>      <th>  No. Observations:  </th>  <td>    42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    28</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1854.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 05 Feb 2018</td> <th>  Deviance:          </th> <td>  3394.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>15:32:30</td>     <th>  Pearson chi2:      </th> <td>3.24e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barking and Dagenham]</th> <td>    6.8347</td> <td>    0.044</td> <td>  156.514</td> <td> 0.000</td> <td>    6.749</td> <td>    6.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barnet]</th>               <td>    7.2600</td> <td>    0.040</td> <td>  180.410</td> <td> 0.000</td> <td>    7.181</td> <td>    7.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bexley]</th>               <td>    7.8639</td> <td>    0.041</td> <td>  191.386</td> <td> 0.000</td> <td>    7.783</td> <td>    7.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Brent]</th>                <td>    6.7164</td> <td>    0.040</td> <td>  166.610</td> <td> 0.000</td> <td>    6.637</td> <td>    6.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bromley]</th>              <td>    8.5412</td> <td>    0.043</td> <td>  198.893</td> <td> 0.000</td> <td>    8.457</td> <td>    8.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Camden]</th>               <td>    5.9904</td> <td>    0.040</td> <td>  148.536</td> <td> 0.000</td> <td>    5.911</td> <td>    6.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[City of London]</th>       <td>    2.9570</td> <td>    0.065</td> <td>   45.303</td> <td> 0.000</td> <td>    2.829</td> <td>    3.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Barnet]</th>             <td>    3.1301</td> <td>    0.042</td> <td>   75.198</td> <td> 0.000</td> <td>    3.049</td> <td>    3.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bexley]</th>             <td>    1.3436</td> <td>    0.043</td> <td>   31.101</td> <td> 0.000</td> <td>    1.259</td> <td>    1.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Brent]</th>              <td>    2.6288</td> <td>    0.042</td> <td>   63.330</td> <td> 0.000</td> <td>    2.547</td> <td>    2.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bromley]</th>            <td>    2.5919</td> <td>    0.041</td> <td>   63.220</td> <td> 0.000</td> <td>    2.512</td> <td>    2.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Camden]</th>             <td>    3.7158</td> <td>    0.040</td> <td>   92.597</td> <td> 0.000</td> <td>    3.637</td> <td>    3.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.City of London]</th>     <td>    4.0190</td> <td>    0.040</td> <td>  101.123</td> <td> 0.000</td> <td>    3.941</td> <td>    4.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist</th>                       <td>   -0.0002</td> <td> 1.09e-06</td> <td> -160.256</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Total   No. Observations:                   42\n",
       "Model:                            GLM   Df Residuals:                       28\n",
       "Model Family:                 Poisson   Df Model:                           13\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -1854.4\n",
       "Date:                Mon, 05 Feb 2018   Deviance:                       3394.5\n",
       "Time:                        15:32:30   Pearson chi2:                 3.24e+03\n",
       "No. Iterations:                     8                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Orig[Barking and Dagenham]     6.8347      0.044    156.514      0.000       6.749       6.920\n",
       "Orig[Barnet]                   7.2600      0.040    180.410      0.000       7.181       7.339\n",
       "Orig[Bexley]                   7.8639      0.041    191.386      0.000       7.783       7.944\n",
       "Orig[Brent]                    6.7164      0.040    166.610      0.000       6.637       6.795\n",
       "Orig[Bromley]                  8.5412      0.043    198.893      0.000       8.457       8.625\n",
       "Orig[Camden]                   5.9904      0.040    148.536      0.000       5.911       6.069\n",
       "Orig[City of London]           2.9570      0.065     45.303      0.000       2.829       3.085\n",
       "Dest[T.Barnet]                 3.1301      0.042     75.198      0.000       3.049       3.212\n",
       "Dest[T.Bexley]                 1.3436      0.043     31.101      0.000       1.259       1.428\n",
       "Dest[T.Brent]                  2.6288      0.042     63.330      0.000       2.547       2.710\n",
       "Dest[T.Bromley]                2.5919      0.041     63.220      0.000       2.512       2.672\n",
       "Dest[T.Camden]                 3.7158      0.040     92.597      0.000       3.637       3.794\n",
       "Dest[T.City of London]         4.0190      0.040    101.123      0.000       3.941       4.097\n",
       "dist                          -0.0002   1.09e-06   -160.256      0.000      -0.000      -0.000\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a production constrained SIM with a negative exponential cost function.\n",
    "formula = \"Total ~ Orig + Dest + dist -1\"\n",
    "doubSimExp = smf.glm(formula=formula, data = cdatasub, family = sm.families.Poisson()).fit()\n",
    "doubSimExp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>3151.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>6975.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>484.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4690.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>7041.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5059.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>4647.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>153.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>10733.0</td>\n",
       "      <td>17332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8179.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40726.0</td>\n",
       "      <td>93804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   266.0   663.0    99.0    371.0   \n",
       "Barnet                                18.0     0.0    29.0  5277.0     63.0   \n",
       "Bexley                               484.0   319.0     0.0   177.0   4690.0   \n",
       "Brent                                  6.0  5059.0    16.0     0.0     55.0   \n",
       "Bromley                              153.0   390.0  2650.0   352.0      0.0   \n",
       "Camden                                12.0  2049.0    28.0  1424.0     77.0   \n",
       "City of London                         1.0    39.0     4.0    27.0     10.0   \n",
       "All                                  674.0  8122.0  3390.0  7356.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1125.0          3151.0   5675.0  \n",
       "Barnet                13100.0          6975.0  25462.0  \n",
       "Bexley                 1975.0          7041.0  14686.0  \n",
       "Brent                  8725.0          4647.0  18508.0  \n",
       "Bromley                3054.0         10733.0  17332.0  \n",
       "Camden                    0.0          8179.0  11769.0  \n",
       "City of London          291.0             0.0    372.0  \n",
       "All                   28270.0         40726.0  93804.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the estimates\n",
    "cdatasub['doubsimfitted_exp'] = np.round(doubSimExp.predict())\n",
    "# Here's the matrix\n",
    "pd.pivot_table(cdatasub,values='doubsimfitted_exp',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared = 0.984304400522\n",
      "RMSE = 413.249377034\n"
     ]
    }
   ],
   "source": [
    "# Now look at the goodness of fit statistics.\n",
    "# Now, the goodness of fit for the doubly constrained model with the exponential cost function.\n",
    "# The model fits slightly better than with an negative exponential!\n",
    "print \"R squared =\", calcR2(cdatasub['Total'],cdatasub['doubsimfitted_exp'])\n",
    "print \"RMSE =\", calcRMSE(cdatasub['Total'],cdatasub['doubsimfitted_exp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that using a negative exponential function in our model actually improves the fit.\n",
    "\n",
    "## 4.1.2 Adding some more variables\n",
    "\n",
    "Yes, the nice thing about doing all of this in a regression modelling framework is we can just keep adding predictor variables into the mix and seeing whether they have an effect.\n",
    "\n",
    "You can’t add origin or destination specific predictors into a doubly constrained model like this, however, you could add some interaction predictors. For example, instead of modelling total flows, we could try and model motorbike commuters using information on car and underground commuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Total</td>      <th>  No. Observations:  </th>  <td>    42</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1587.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 05 Feb 2018</td> <th>  Deviance:          </th> <td>  2860.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>10:35:28</td>     <th>  Pearson chi2:      </th> <td>2.61e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barking and Dagenham]</th> <td>    6.4837</td> <td>    0.048</td> <td>  134.924</td> <td> 0.000</td> <td>    6.390</td> <td>    6.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Barnet]</th>               <td>    7.0348</td> <td>    0.051</td> <td>  137.035</td> <td> 0.000</td> <td>    6.934</td> <td>    7.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bexley]</th>               <td>    7.2706</td> <td>    0.050</td> <td>  145.884</td> <td> 0.000</td> <td>    7.173</td> <td>    7.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Brent]</th>                <td>    6.6298</td> <td>    0.044</td> <td>  149.458</td> <td> 0.000</td> <td>    6.543</td> <td>    6.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Bromley]</th>              <td>    7.8815</td> <td>    0.053</td> <td>  149.197</td> <td> 0.000</td> <td>    7.778</td> <td>    7.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[Camden]</th>               <td>    6.2885</td> <td>    0.046</td> <td>  135.766</td> <td> 0.000</td> <td>    6.198</td> <td>    6.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Orig[City of London]</th>       <td>    3.0735</td> <td>    0.065</td> <td>   47.038</td> <td> 0.000</td> <td>    2.945</td> <td>    3.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Barnet]</th>             <td>    2.3484</td> <td>    0.051</td> <td>   46.130</td> <td> 0.000</td> <td>    2.249</td> <td>    2.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bexley]</th>             <td>    1.0582</td> <td>    0.045</td> <td>   23.671</td> <td> 0.000</td> <td>    0.971</td> <td>    1.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Brent]</th>              <td>    1.8990</td> <td>    0.050</td> <td>   37.642</td> <td> 0.000</td> <td>    1.800</td> <td>    1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Bromley]</th>            <td>    1.9777</td> <td>    0.049</td> <td>   40.528</td> <td> 0.000</td> <td>    1.882</td> <td>    2.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.Camden]</th>             <td>    3.3924</td> <td>    0.043</td> <td>   79.370</td> <td> 0.000</td> <td>    3.309</td> <td>    3.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dest[T.City of London]</th>     <td>    3.8821</td> <td>    0.040</td> <td>   97.071</td> <td> 0.000</td> <td>    3.804</td> <td>    3.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist</th>                       <td>   -0.0001</td> <td> 1.98e-06</td> <td>  -68.954</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CarDrive</th>                   <td>    0.0002</td> <td> 9.26e-06</td> <td>   22.129</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Underground</th>                <td>-8.288e-05</td> <td> 5.44e-06</td> <td>  -15.247</td> <td> 0.000</td> <td>-9.35e-05</td> <td>-7.22e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  Total   No. Observations:                   42\n",
       "Model:                            GLM   Df Residuals:                       26\n",
       "Model Family:                 Poisson   Df Model:                           15\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -1587.6\n",
       "Date:                Mon, 05 Feb 2018   Deviance:                       2860.9\n",
       "Time:                        10:35:28   Pearson chi2:                 2.61e+03\n",
       "No. Iterations:                     8                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Orig[Barking and Dagenham]     6.4837      0.048    134.924      0.000       6.390       6.578\n",
       "Orig[Barnet]                   7.0348      0.051    137.035      0.000       6.934       7.135\n",
       "Orig[Bexley]                   7.2706      0.050    145.884      0.000       7.173       7.368\n",
       "Orig[Brent]                    6.6298      0.044    149.458      0.000       6.543       6.717\n",
       "Orig[Bromley]                  7.8815      0.053    149.197      0.000       7.778       7.985\n",
       "Orig[Camden]                   6.2885      0.046    135.766      0.000       6.198       6.379\n",
       "Orig[City of London]           3.0735      0.065     47.038      0.000       2.945       3.202\n",
       "Dest[T.Barnet]                 2.3484      0.051     46.130      0.000       2.249       2.448\n",
       "Dest[T.Bexley]                 1.0582      0.045     23.671      0.000       0.971       1.146\n",
       "Dest[T.Brent]                  1.8990      0.050     37.642      0.000       1.800       1.998\n",
       "Dest[T.Bromley]                1.9777      0.049     40.528      0.000       1.882       2.073\n",
       "Dest[T.Camden]                 3.3924      0.043     79.370      0.000       3.309       3.476\n",
       "Dest[T.City of London]         3.8821      0.040     97.071      0.000       3.804       3.960\n",
       "dist                          -0.0001   1.98e-06    -68.954      0.000      -0.000      -0.000\n",
       "CarDrive                       0.0002   9.26e-06     22.129      0.000       0.000       0.000\n",
       "Underground                -8.288e-05   5.44e-06    -15.247      0.000   -9.35e-05   -7.22e-05\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, use a bunch more variables for prediction\n",
    "formula = \"Total ~ Orig + Dest + dist + CarDrive + Underground -1\"\n",
    "kitchensinkSIM = smf.glm(formula=formula, data = cdatasub, family = sm.families.Poisson()).fit()\n",
    "kitchensinkSIM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having fit this new 'kitchen sink' model, we can predict the flows as standard and have a look at the flow matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5459.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>13603.0</td>\n",
       "      <td>6212.0</td>\n",
       "      <td>25461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>409.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>7250.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5328.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>8155.0</td>\n",
       "      <td>4888.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>174.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>10825.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8230.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>673.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>7357.0</td>\n",
       "      <td>5265.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40725.0</td>\n",
       "      <td>93801.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   228.0   513.0    99.0    306.0   \n",
       "Barnet                                37.0     0.0    55.0  5459.0     95.0   \n",
       "Bexley                               409.0   255.0     0.0   152.0   4624.0   \n",
       "Brent                                 17.0  5328.0    34.0     0.0     86.0   \n",
       "Bromley                              174.0   323.0  2712.0   283.0      0.0   \n",
       "Camden                                34.0  1954.0    69.0  1340.0    142.0   \n",
       "City of London                         2.0    34.0     6.0    24.0     12.0   \n",
       "All                                  673.0  8122.0  3389.0  7357.0   5265.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1209.0          3320.0   5675.0  \n",
       "Barnet                13603.0          6212.0  25461.0  \n",
       "Bexley                 1996.0          7250.0  14686.0  \n",
       "Brent                  8155.0          4888.0  18508.0  \n",
       "Bromley                3014.0         10825.0  17331.0  \n",
       "Camden                    0.0          8230.0  11769.0  \n",
       "City of London          293.0             0.0    371.0  \n",
       "All                   28270.0         40725.0  93801.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdatasub['kitchensink'] = np.round(kitchensinkSIM.predict())\n",
    "pd.pivot_table(cdatasub,values='kitchensink',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check the model against the observed flows using the goodness of fit functions previously defined - it looks like this model actually doesn't perform as well as the original doubly constrained spatial interaction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared = 0.979907947328\n",
      "RMSE = 471.829191249\n"
     ]
    }
   ],
   "source": [
    "# This 'kitchen sink' model is actually a worse model than either standard doubly constrained model.\n",
    "\n",
    "print \"R squared =\", calcR2(cdatasub['Total'],cdatasub['kitchensink'])\n",
    "print \"RMSE =\", calcRMSE(cdatasub['Total'],cdatasub['kitchensink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Poisson Regression back to Entropy\n",
    "\n",
    "As with the earlier models, I have shown you how you can plug the parameter estimates back into Wilson’s entropy maximising multiplicative models in order to generate estimates and tweak things still further.\n",
    "\n",
    "If you remember from Equations 11 and 12 above, the key to the doubly constrained models is the $A_{i}$ and $B_{j}$ balancing factors and as they rely on each other, they need to be calculated iteratively. We can do this using Senior’s algorthm also mentioned earlier.\n",
    "\n",
    "In a departure from Dennett, I've rewritten the algorithm as a function, which can then be called subject to the required parameters. In order for it to work it requires the following things:\n",
    "* pd - a pandas dataframe of origin-destination pairwise flows and associated data.\n",
    "* orig_field - the name of the dataframe field in pd that uniquely labels origin zones.\n",
    "* dest_field - the name of the dataframe field in pd that uniquely labels destination zones.\n",
    "* Oi_field - the name of the dataframe field that stores total flows from a given origin $i$\n",
    "* Dj_field - the name of the dataframe field that stores total flows to a given destination $j$\n",
    "* cij_field - the name of the dataframe field that stores the pairwise cost (e.g. distance) between $i$ and $j$\n",
    "* beta - a constant for the beta parameter you wish to use in the model\n",
    "* cost_function - a string representing the cost function, either 'power' or 'exponential'\n",
    "* Ai_name - What you want to call the new field in pd that will hold $A_{i}$ values, defaults to \"Ai_new\"\n",
    "* Bj_name - What you want to call the new field in pd that will hold $B_{j}$ values, defaults to \"Bj_new\"\n",
    "* converge - A threshold value at which a model can be said to have converged, the default of 0.001 seems to work fine.\n",
    "\n",
    "NB Remember that we calculated $O_{i}$ and $D_{j}$ earlier, they are simply the total flows by either origin or destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the entropy maximising approach for a known beta.\n",
    "# Plug in the required values in this function to solve.\n",
    "\n",
    "def balance_doubly_constrained(pd, orig_field, dest_field, Oi_field, Dj_field, cij_field, beta, \n",
    "                               cost_function, Ai_name = \"Ai_new\", Bj_name = \"Bj_new\", converge=0.001):\n",
    "    # Define some variables\n",
    "    Oi = pd[[orig_field, Oi_field]]\n",
    "    Dj = pd[[dest_field,Dj_field]]    \n",
    "    if cost_function.lower() in ['power','pow']:\n",
    "        beta_cij = np.exp(beta * np.log(pd[cij_field]))\n",
    "    elif cost_function.lower() in ['exponential','exp']:\n",
    "        beta_cij = np.exp(beta * pd[cij_field])\n",
    "    else:\n",
    "        return \"Cost function not specified properly, use 'exp' or 'pow'\"\n",
    "    \n",
    "    # Create some helper variables\n",
    "    cnvg = 1\n",
    "    iteration = 0\n",
    "    # Now iteratively rebalance the Ai and Bj terms until convergence\n",
    "    while cnvg > converge:\n",
    "        if iteration == 0:\n",
    "            # This first condition sets starting values for Ai and Bj\n",
    "            # NB sets starting value of Ai assuming Bj is a vector of 1s.\n",
    "            # We've already established beta_cij with the appropriate cost function, so...\n",
    "            Oi = Oi.assign(Ai = Dj[Dj_field] * beta_cij)\n",
    "            # Aggregate Ai and take inverse\n",
    "            Ai = 1.0/Oi.groupby(orig_field)['Ai'].sum().to_frame()\n",
    "            # Merge new Ais \n",
    "            Oi = Oi.merge(Ai,left_on = orig_field, right_index = True, suffixes = ('','_old'))\n",
    "            # Drop the temporary Ai field we created, leaving Ai_old\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            \n",
    "            # Now set up Bjs using starting values of Ai\n",
    "            Dj = Dj.assign(Bj = Oi['Ai_old'] * Oi[Oi_field] * beta_cij)\n",
    "            # Aggregate Bj and take inverse\n",
    "            Bj = 1.0/Dj.groupby(dest_field)['Bj'].sum().to_frame()\n",
    "            # Merge new Bjs\n",
    "            Dj = Dj.merge(Bj,left_on = dest_field, right_index = True, suffixes = ('','_old'))\n",
    "            # Drop the temporary Bj field we created, leaving Bj_old\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            \n",
    "            # Increment loop\n",
    "            iteration += 1\n",
    "        else:\n",
    "            # This bit is the iterated bit of the loop which refines the values of Ai and Bj\n",
    "            # First Ai\n",
    "            Oi['Ai'] = Dj['Bj_old'] * Dj[Dj_field] * beta_cij\n",
    "            # Aggregate Ai and take inverse\n",
    "            Ai = 1.0/Oi.groupby(orig_field)['Ai'].sum().to_frame()\n",
    "            # Drop temporary Ai\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            # Merge new Ais \n",
    "            Oi = Oi.merge(Ai,left_on = orig_field, right_index = True)\n",
    "            # Calculate the difference between old and new Ais\n",
    "            Oi['diff'] = np.absolute((Oi['Ai_old'] - Oi['Ai'])/Oi['Ai_old'])\n",
    "            # Set new Ais to Ai_old\n",
    "            Oi['Ai_old'] = Oi['Ai']\n",
    "            # Drop the temporary Ai field we created, leaving Ai_old\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            \n",
    "            # Then Bj\n",
    "            Dj['Bj'] = Oi['Ai_old'] * Oi[Oi_field] * beta_cij\n",
    "            # Aggregate Bj and take inverse\n",
    "            Bj = 1.0/Dj.groupby(dest_field)['Bj'].sum().to_frame()\n",
    "            # Drop temporary Bj\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            # Merge new Bjs\n",
    "            Dj = Dj.merge(Bj,left_on = dest_field, right_index = True)\n",
    "            # Calculate the difference between old and new Bjs\n",
    "            Dj['diff'] = np.absolute((Dj['Bj_old'] - Dj['Bj'])/Dj['Bj_old'])\n",
    "            # Set new Bjs to Bj_old\n",
    "            Dj['Bj_old'] = Dj['Bj']\n",
    "            # Drop the temporary Bj field we created, leaving Bj_old\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            \n",
    "            # Assign higher sum difference from Ai or Bj to cnvg\n",
    "            cnvg = np.maximum(Oi['diff'].sum(),Dj['diff'].sum())\n",
    "            \n",
    "            # Print and increment loop\n",
    "            print \"Iteration:\", iteration\n",
    "            iteration += 1\n",
    "\n",
    "    # When the while loop finishes add the computed Ai_old and Bj_old to the dataframe and return\n",
    "    pd[Ai_name] = Oi['Ai_old']\n",
    "    pd[Bj_name] = Dj['Bj_old']\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above we can calculate $A_{i}$ and $B_{j}$ for the previous Poisson model by plugging in the estimate of beta that we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>3055.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5542.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>12967.0</td>\n",
       "      <td>6674.0</td>\n",
       "      <td>25461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>490.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>4492.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>6871.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5288.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>8893.0</td>\n",
       "      <td>4162.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>141.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>10226.0</td>\n",
       "      <td>17331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9736.0</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8123.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5267.0</td>\n",
       "      <td>28269.0</td>\n",
       "      <td>40724.0</td>\n",
       "      <td>93803.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   317.0   773.0   137.0    404.0   \n",
       "Barnet                                25.0     0.0    69.0  5542.0    184.0   \n",
       "Bexley                               490.0   554.0     0.0   301.0   4492.0   \n",
       "Brent                                 10.0  5288.0    36.0     0.0    119.0   \n",
       "Bromley                              141.0   813.0  2487.0   550.0      0.0   \n",
       "Camden                                 7.0  1131.0    22.0   813.0     61.0   \n",
       "City of London                         1.0    20.0     3.0    13.0      7.0   \n",
       "All                                  674.0  8123.0  3390.0  7356.0   5267.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham    989.0          3055.0   5675.0  \n",
       "Barnet                12967.0          6674.0  25461.0  \n",
       "Bexley                 1978.0          6871.0  14686.0  \n",
       "Brent                  8893.0          4162.0  18508.0  \n",
       "Bromley                3114.0         10226.0  17331.0  \n",
       "Camden                    0.0          9736.0  11770.0  \n",
       "City of London          328.0             0.0    372.0  \n",
       "All                   28269.0         40724.0  93803.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the beta we got from the inverse power model\n",
    "beta = doubSim.params[-1]\n",
    "# Get the balancing factors.\n",
    "cdatasub = balance_doubly_constrained(cdatasub,'OrigNewCode','DestNewCode','O_i','D_j','dist',beta,'power')\n",
    "\n",
    "# Now predict the model again using the new Ai and Dj fields.\n",
    "cdatasub['SIM_est_pow'] = np.round(cdatasub['O_i'] * cdatasub['Ai_new'] * cdatasub['D_j'] * cdatasub['Bj_new'] * \n",
    "                                   np.exp(np.log(cdatasub['dist'])*beta))\n",
    "# Check out the matrix\n",
    "pd.pivot_table(cdatasub,values='SIM_est_pow',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dest</th>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>City of London</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barking and Dagenham</th>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>3151.0</td>\n",
       "      <td>5675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>6975.0</td>\n",
       "      <td>25462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>484.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4690.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>7041.0</td>\n",
       "      <td>14686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5059.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>4647.0</td>\n",
       "      <td>18508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bromley</th>\n",
       "      <td>153.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>10733.0</td>\n",
       "      <td>17332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camden</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8179.0</td>\n",
       "      <td>11769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>674.0</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>7356.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>28270.0</td>\n",
       "      <td>40726.0</td>\n",
       "      <td>93804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dest                  Barking and Dagenham  Barnet  Bexley   Brent  Bromley  \\\n",
       "Orig                                                                          \n",
       "Barking and Dagenham                   0.0   266.0   663.0    99.0    371.0   \n",
       "Barnet                                18.0     0.0    29.0  5277.0     63.0   \n",
       "Bexley                               484.0   319.0     0.0   177.0   4690.0   \n",
       "Brent                                  6.0  5059.0    16.0     0.0     55.0   \n",
       "Bromley                              153.0   390.0  2650.0   352.0      0.0   \n",
       "Camden                                12.0  2049.0    28.0  1424.0     77.0   \n",
       "City of London                         1.0    39.0     4.0    27.0     10.0   \n",
       "All                                  674.0  8122.0  3390.0  7356.0   5266.0   \n",
       "\n",
       "Dest                   Camden  City of London      All  \n",
       "Orig                                                    \n",
       "Barking and Dagenham   1125.0          3151.0   5675.0  \n",
       "Barnet                13100.0          6975.0  25462.0  \n",
       "Bexley                 1975.0          7041.0  14686.0  \n",
       "Brent                  8725.0          4647.0  18508.0  \n",
       "Bromley                3054.0         10733.0  17332.0  \n",
       "Camden                    0.0          8179.0  11769.0  \n",
       "City of London          291.0             0.0    372.0  \n",
       "All                   28270.0         40726.0  93804.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the beta we got from the negative exponential model\n",
    "beta = doubSimExp.params[-1]\n",
    "# Get the balancing factors. NB Setting of new field names for Ai and Bj.\n",
    "cdatasub = balance_doubly_constrained(cdatasub,'OrigNewCode','DestNewCode','O_i','D_j','dist',beta,'exponential','Ai_exp','Bj_exp')\n",
    "\n",
    "# Now predict the model again using the new Ai and Dj fields.\n",
    "cdatasub['SIM_est_exp'] = np.round(cdatasub['O_i'] * cdatasub['Ai_exp'] * cdatasub['D_j'] * cdatasub['Bj_exp'] * \n",
    "                                   np.exp(cdatasub['dist']*beta))\n",
    "# Check out the matrix\n",
    "pd.pivot_table(cdatasub,values='SIM_est_exp',index ='Orig',columns='Dest',fill_value=0,aggfunc=sum,margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it all works!\n",
    "\n",
    "# Conclusions, further notes and idea for additional activities\n",
    "\n",
    "Hopefully you have now seen how it is extremely straight-forward to run and calibrate Wilson’s full family of Spatial Interaction Models in Python using a Poisson GLM.\n",
    "\n",
    "## 5.1 Some Further Notes\n",
    "\n",
    "Now might be the time to mention that despite everything I’ve shown you, there has been some discussion in the literature as to whether the Poisson Model is actually a misspecification, especially for modelling migration flows. If you have the stomach for it, [this paper by Congdon](http://journals.sagepub.com/doi/abs/10.1068/a251481) goes into a lot of detail.\n",
    "\n",
    "The issue is a thing called ‘overdispersion’ which, translated, essentially relates to the model not being able to capture all of the things that could be explaining the flows in the independent variables that are supplied to the model. The details are tedious and only really intelligible to those with a statistics background. If you want a starter, [try here](https://en.wikipedia.org/wiki/Overdispersion), but in practical terms, we can get around this problem by fitting a very similar sort of regression model called the negative binomial regression model.\n",
    "\n",
    "If you wish, you can read up and experiment with this model - you can fit it in exactly the same way as the poisson glm model but using: family = sm.families.NegativeBinomial(alpha) when you call the statsmodel glm function. The negative binomial model has an extra parameter - alpha - in the model for overdispersion with a default of 1.\n",
    "\n",
    "Another thing to note is that the example we used here had quite neat data. You will almost certainly run into problems if you have sparse data or predictors with 0s in them. If this happens, then you might need to either drop some rows in your data (if populated with 0s) or substitute 0s for very small numbers, much less than 1, but greater than 0 (this is because you can’t take the log of 0). [Taylor Oshan's SpInt](http://openjournals.wu.ac.at/region/paper_175/175.html) implementation in Python uses a special Poisson regression approach that better handles sparse data structures.\n",
    "\n",
    "And another thing to note is that our flow data and our predictors were all in and around the same order or magnitude. If you suddenly get data that (such as population masses at origins and destinations) that are an order of magnitude different (i.e. populations about ten times larger in different locations) then the model estimates might be biased.\n",
    "\n",
    "## 5.2 Further Activities\n",
    "\n",
    "1. Testing these models out on the whole of London and for different years\n",
    " * You’ve been playing around with just a small 7 borough sample, why not try the full London system. +You can also try and download some similar data from the 2011 Census from [Wicid](http://wicid.ukdataservice.ac.uk/) - see if using $O_{i}$ and $D_{j}$ totals and the parameters calibrated on 2001 data gives you reasonable estimates of the 2011 flows. How have model parameters changed between 2001 and 2011, and how might we interpret that?\n",
    "2. Visualising your flow estimates\n",
    " * try using some of the basic visualisation we did in the unconstrained SIM practical to visualise some flow estimates, or flow residuals.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
